{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet10 with CIFAR10 dataset - Study Optimization\n",
        "\n"
      ],
      "metadata": {
        "id": "732RXgD-pCXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G8bSmKbGpBfz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "try:\n",
        "    from torchsummary import summary\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torchsummary\n",
        "    from torchsummary import summary\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.RandomAffine(degrees=10, shear = 10),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n",
        "\n",
        "train = datasets.CIFAR10(root = './data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "# Do we have CUDA drivers for us?\n",
        "cuda = torch.cuda.is_available()\n",
        "print (\"Cuda Available?\", cuda)\n",
        "\n",
        "dataloader_args = dict(shuffle=True, batch_size=2048, num_workers=2, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, **dataloader_args)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, **dataloader_args)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yxR2s92RqM",
        "outputId": "4e9bdd3e-2336-4323-b3a5-1502b18ef1f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Cuda Available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv01 = nn.Conv2d(3, 16, 3, bias=False, padding=1)\n",
        "        self.batch01 = nn.BatchNorm2d(num_features=16)\n",
        "\n",
        "        # ---- Lets take a skip connection\n",
        "        self.skip_conv1 = nn.Conv2d(16, 16, 3, padding=0, dilation=2)\n",
        "\n",
        "        self.conv02 = nn.Conv2d(16, 16, 3, bias=False,padding=1)\n",
        "        self.batch02 = nn.BatchNorm2d(num_features=16)\n",
        "        self.conv03 = nn.Conv2d(16, 16, 3, bias=False,padding=1)\n",
        "        self.batch03 = nn.BatchNorm2d(num_features=16)\n",
        "        self.conv04 = nn.Conv2d(16, 16, 3, bias=False,padding=1)\n",
        "        self.batch04 = nn.BatchNorm2d(num_features=16)\n",
        "        self.pool01 = nn.MaxPool2d(2, 2)                                #O=16\n",
        "        self.conv05 = nn.Conv2d(16, 16, 1, bias=False)\n",
        "\n",
        "        self.conv11 = nn.Conv2d(16, 32, 3, bias=False, padding=1)\n",
        "        self.batch11 = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv12 = nn.Conv2d(32, 32, 3, bias=False, padding=1)\n",
        "        self.batch12 = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv13 = nn.Conv2d(32, 32, 3, bias=False, padding=1)\n",
        "        self.batch13 = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv14 = nn.Conv2d(32, 32, 3, bias=False, padding=1)\n",
        "        self.batch14 = nn.BatchNorm2d(num_features=32)\n",
        "        self.pool11 = nn.MaxPool2d(2, 2)                                #O=8\n",
        "        self.conv15 = nn.Conv2d(32, 32, 1, bias=False)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(32, 64, 3, bias=False, padding=1)\n",
        "        self.batch21 = nn.BatchNorm2d(num_features=64)\n",
        "        self.conv22 = nn.Conv2d(64, 64, 3, bias=False, padding=1)\n",
        "        self.batch22 = nn.BatchNorm2d(num_features=64)\n",
        "        self.conv23 = nn.Conv2d(64, 64, 3, bias=False, padding=1)\n",
        "        self.batch23 = nn.BatchNorm2d(num_features=64)\n",
        "        self.conv24 = nn.Conv2d(64, 64, 3, bias=False, padding=1)\n",
        "        self.batch24 = nn.BatchNorm2d(num_features=64)\n",
        "        self.pool21 = nn.MaxPool2d(2, 2)                                #O=4\n",
        "        self.conv25 = nn.Conv2d(64, 64, 1, bias=False)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, groups=64, bias = False, padding = 1)\n",
        "        self.convPV1= nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1, bias = False, padding = 0)\n",
        "        self.batch31 = nn.BatchNorm2d(num_features=128)\n",
        "        self.conv32 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, groups=128, bias = False, padding = 1)\n",
        "        self.convPV2= nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1, bias = False, padding = 0)\n",
        "        self.batch32 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=4)\n",
        "        self.convx3 = nn.Conv2d(256, 10, 1, bias=False, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch01(F.relu(self.conv01(x)))\n",
        "\n",
        "        # ---- Lets take a skip connection\n",
        "        skip_channels = self.skip_conv1(self.skip_conv1(self.skip_conv1(self.skip_conv1(x))))\n",
        "\n",
        "        x = self.batch02(F.relu(self.conv02(x)))\n",
        "        x = self.batch03(F.relu(self.conv03(x)))\n",
        "        x = self.batch04(F.relu(self.conv04(x)))\n",
        "        x = self.pool01(x)\n",
        "        x = self.conv05(x)\n",
        "        # ----------------------------------------------------------\n",
        "\n",
        "        # ---- Lets add the skip connection here\n",
        "        x = skip_channels + x\n",
        "\n",
        "        x = self.batch11(F.relu(self.conv11(x)))\n",
        "        x = self.batch12(F.relu(self.conv12(x)))\n",
        "        x = self.batch13(F.relu(self.conv13(x)))\n",
        "        x = self.batch14(F.relu(self.conv14(x)))\n",
        "        x = self.pool11(x)\n",
        "        x = self.conv15(x)\n",
        "        # ----------------------------------------------------------\n",
        "\n",
        "        x = self.batch21(F.relu(self.conv21(x)))\n",
        "        x = self.batch22(F.relu(self.conv22(x)))\n",
        "        x = self.batch23(F.relu(self.conv23(x)))\n",
        "        x = self.batch24(F.relu(self.conv24(x)))\n",
        "        x = self.pool21(x)\n",
        "        x = self.conv25(x)\n",
        "        # ----------------------------------------------------------\n",
        "\n",
        "        x = self.batch31(F.relu(self.convPV1(F.relu(self.conv31(x)))))\n",
        "        x = self.batch32(F.relu(self.convPV2(F.relu(self.conv32(x)))))\n",
        "\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.convx3(x)\n",
        "        x = x.view(-1, 10)                           # Don't want 10x1x1..\n",
        "        return F.log_softmax(x, dim=1)  # Added dim=1 parameter)"
      ],
      "metadata": {
        "id": "K10_ILasJFly"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZsEKXnM7Iao",
        "outputId": "fa472104-e7e9-4750-e249-cd93de95a51d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 28, 28]           2,320\n",
            "            Conv2d-4           [-1, 16, 24, 24]           2,320\n",
            "            Conv2d-5           [-1, 16, 20, 20]           2,320\n",
            "            Conv2d-6           [-1, 16, 16, 16]           2,320\n",
            "            Conv2d-7           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            "            Conv2d-9           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-10           [-1, 16, 32, 32]              32\n",
            "           Conv2d-11           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-12           [-1, 16, 32, 32]              32\n",
            "        MaxPool2d-13           [-1, 16, 16, 16]               0\n",
            "           Conv2d-14           [-1, 16, 16, 16]             256\n",
            "           Conv2d-15           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-16           [-1, 32, 16, 16]              64\n",
            "           Conv2d-17           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-18           [-1, 32, 16, 16]              64\n",
            "           Conv2d-19           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-20           [-1, 32, 16, 16]              64\n",
            "           Conv2d-21           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-22           [-1, 32, 16, 16]              64\n",
            "        MaxPool2d-23             [-1, 32, 8, 8]               0\n",
            "           Conv2d-24             [-1, 32, 8, 8]           1,024\n",
            "           Conv2d-25             [-1, 64, 8, 8]          18,432\n",
            "      BatchNorm2d-26             [-1, 64, 8, 8]             128\n",
            "           Conv2d-27             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
            "           Conv2d-29             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-30             [-1, 64, 8, 8]             128\n",
            "           Conv2d-31             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-32             [-1, 64, 8, 8]             128\n",
            "        MaxPool2d-33             [-1, 64, 4, 4]               0\n",
            "           Conv2d-34             [-1, 64, 4, 4]           4,096\n",
            "           Conv2d-35             [-1, 64, 4, 4]             576\n",
            "           Conv2d-36            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-37            [-1, 128, 4, 4]             256\n",
            "           Conv2d-38            [-1, 128, 4, 4]           1,152\n",
            "           Conv2d-39            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-40            [-1, 256, 4, 4]             512\n",
            "        AvgPool2d-41            [-1, 256, 1, 1]               0\n",
            "           Conv2d-42             [-1, 10, 1, 1]           2,560\n",
            "================================================================\n",
            "Total params: 230,192\n",
            "Trainable params: 230,192\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.22\n",
            "Params size (MB): 0.88\n",
            "Estimated Total Size (MB): 3.11\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "time_taken = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    time_taken.clear()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate (pbar):\n",
        "        t0 = time.time()\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        #Don't want history of gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_predict = model(data)\n",
        "\n",
        "        # Caluclate loss\n",
        "        loss = F.nll_loss(y_predict, target)\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        # Back propogate error\n",
        "        loss.backward()\n",
        "\n",
        "        # Take a optimzer step\n",
        "        optimizer.step()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        t1 = time.time()\n",
        "\n",
        "        time_taken.append((t1-t0))\n",
        "\n",
        "        pred = y_predict.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        # print(f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f} Time taken per iter = {dt :.2f}ms')\n",
        "        pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "        train_acc.append(100*correct/processed)\n",
        "\n",
        "\n",
        "def test (model, device, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "\n",
        "model =  Net().to(device)\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
        "\n",
        "EPOCHS = 5\n",
        "for epoch in range(EPOCHS):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    print(f\" --> EPOCH: {epoch}, Avg Time Taken = {(sum(time_taken)/len(time_taken))*1000:.2f}ms\")\n",
        "    # scheduler.step()\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "id": "MMVJZShF7YfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64eec8a-2c58-4443-dacc-59ec0d17d533"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.806193470954895 Batch_id=24 Accuracy=21.56: 100%|██████████| 25/25 [00:25<00:00,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 0, Avg Time Taken = 337.22ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3172, Accuracy: 1002/10000 (10.02%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.5318331718444824 Batch_id=24 Accuracy=37.21: 100%|██████████| 25/25 [00:17<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 1, Avg Time Taken = 310.68ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6515, Accuracy: 3741/10000 (37.41%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.4526479244232178 Batch_id=24 Accuracy=45.36: 100%|██████████| 25/25 [00:17<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 2, Avg Time Taken = 310.49ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4293, Accuracy: 4796/10000 (47.96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.2338448762893677 Batch_id=24 Accuracy=51.04: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 3, Avg Time Taken = 311.87ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2852, Accuracy: 5269/10000 (52.69%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.181266188621521 Batch_id=24 Accuracy=55.43: 100%|██████████| 25/25 [00:17<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 4, Avg Time Taken = 313.12ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2248, Accuracy: 5603/10000 (56.03%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check if BF16 is available or not. If not available, progress with FP16"
      ],
      "metadata": {
        "id": "AqznsN0D9hjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def check_bf16_support():\n",
        "    if torch.cuda.is_available():\n",
        "        compute_capability = torch.cuda.get_device_capability()\n",
        "        # Ampere (8.x) and newer GPUs support BF16\n",
        "        return compute_capability[0] >= 8\n",
        "    return False\n",
        "\n",
        "check_bf16_support()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSw1HmpymZoZ",
        "outputId": "54b631ef-f4f6-4b7b-fc3f-ddac1231ac9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.amp import autocast, GradScaler  # Updated import\n",
        "torch.backends.cudnn.benchmark = True\n",
        "n_epochs = 5\n",
        "\n",
        "# 1. Setup model and optimizer with FP16 support\n",
        "def setup_fp16_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = torch.compile(Net().to(device))\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=n_epochs)\n",
        "    # Updated GradScaler initialization\n",
        "    scaler = GradScaler('cuda')\n",
        "\n",
        "    return model, optimizer, scaler, device\n",
        "\n",
        "# 2. Modified training loop\n",
        "def train(model, device, train_loader, optimizer, scaler, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    time_taken.clear()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Convert data to FP16 before moving to GPU\n",
        "        data = data.half()  # Convert to FP16\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Updated autocast\n",
        "        with autocast('cuda', dtype=torch.float16):\n",
        "            y_predict = model(data)\n",
        "            loss = F.nll_loss(y_predict, target)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        # scheduler.step()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        t1 = time.time()\n",
        "\n",
        "        time_taken.append((t1-t0))\n",
        "\n",
        "        pred = y_predict.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        pbar.set_description(desc=f'Loss={loss.item()} Batch_idx={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "        train_acc.append(100*correct/processed)\n",
        "\n",
        "# 3. Modified test loop\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "\n",
        "            # Convert data to FP16 before moving to GPU\n",
        "            data = data.half()  # Convert to FP16\n",
        "\n",
        "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
        "\n",
        "            # Updated autocast\n",
        "            with autocast('cuda'):\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "# 4. Training setup and execution\n",
        "model, optimizer, scaler, device = setup_fp16_model()\n",
        "\n",
        "# Your training loop\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    # print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, scaler, epoch)\n",
        "    print(f\" --> EPOCH: {epoch}, Avg Time Taken = {(sum(time_taken)/len(time_taken))*1000:.2f}ms\")\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TVLe-WnocLm",
        "outputId": "9de5d7aa-a9d7-48d9-b826-890d06f1a65e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.9276012182235718 Batch_idx=24 Accuracy=18.97: 100%|██████████| 25/25 [01:54<00:00,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 1, Avg Time Taken = 4122.79ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3071, Accuracy: 1000/10000 (10.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.5672558546066284 Batch_idx=24 Accuracy=35.26: 100%|██████████| 25/25 [00:22<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 2, Avg Time Taken = 191.65ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6947, Accuracy: 3696/10000 (36.96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.38279390335083 Batch_idx=24 Accuracy=44.84: 100%|██████████| 25/25 [00:17<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 3, Avg Time Taken = 124.75ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4096, Accuracy: 4870/10000 (48.70%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.3067739009857178 Batch_idx=24 Accuracy=50.84: 100%|██████████| 25/25 [00:16<00:00,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 4, Avg Time Taken = 124.67ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3127, Accuracy: 5226/10000 (52.26%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.1495048999786377 Batch_idx=24 Accuracy=54.93: 100%|██████████| 25/25 [00:16<00:00,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --> EPOCH: 5, Avg Time Taken = 123.98ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2624, Accuracy: 5433/10000 (54.33%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRmfbiA6-GwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code for BFP16 support"
      ],
      "metadata": {
        "id": "fEAgBmMo-aHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup model and optimizer with BF16 support\n",
        "# def setup_bf16_model(model):\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#     # Enable BF16 autocast\n",
        "#     torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "#     # Convert model to BF16\n",
        "#     model = Net().to(device).to(torch.bfloat16)\n",
        "#     model = torch.compile(model)\n",
        "\n",
        "#     optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#     return model, optimizer, device\n",
        "\n",
        "# # 2. Modified training loop for BF16\n",
        "# def train(model, device, train_loader, optimizer, epoch):\n",
        "#     model.train()\n",
        "#     pbar = tqdm(train_loader)\n",
        "\n",
        "#     correct = 0\n",
        "#     processed = 0\n",
        "#     time_taken.clear()\n",
        "\n",
        "#     for batch_idx, (data, target) in enumerate(pbar):\n",
        "#         t0 = time.time()\n",
        "\n",
        "#         # Convert input to BF16\n",
        "#         data = data.to(torch.bfloat16)\n",
        "#         data, target = data.to(device), target.to(device)\n",
        "\n",
        "#         optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "#         # Use automatic mixed precision with BF16\n",
        "#         with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "#             output = model(data)\n",
        "#             loss = F.nll_loss(output, target)\n",
        "\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         torch.cuda.synchronize()\n",
        "#         t1 = time.time()\n",
        "\n",
        "#         time_taken.append((t1-t0))\n",
        "\n",
        "#         pred = output.argmax(dim=1, keepdim=True)\n",
        "#         correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "#         processed += len(data)\n",
        "\n",
        "#         pbar.set_description(\n",
        "#             desc=f'Loss={loss.item():.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}'\n",
        "#         )\n",
        "#         train_acc.append(100*correct/processed)\n",
        "\n",
        "# # 3. Modified test loop for BF16\n",
        "# def test(model, device, test_loader):\n",
        "#     model.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for data, target in test_loader:\n",
        "#             # Convert input to BF16\n",
        "#             data = data.to(torch.bfloat16)\n",
        "#             data, target = data.to(device), target.to(device)\n",
        "\n",
        "#             with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "#                 output = model(data)\n",
        "#                 test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "\n",
        "#             pred = output.argmax(dim=1, keepdim=True)\n",
        "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "#     test_loss /= len(test_loader.dataset)\n",
        "#     test_losses.append(test_loss)\n",
        "\n",
        "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "#         test_loss, correct, len(test_loader.dataset),\n",
        "#         100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "#     test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "# # 4. Training setup and execution\n",
        "# model, optimizer, device = setup_bf16_model(model)\n",
        "\n",
        "# # Training loop\n",
        "# for epoch in range(1, n_epochs + 1):\n",
        "#     train(model, device, train_loader, optimizer, epoch)\n",
        "#     print(f\" --> EPOCH: {epoch}, Avg Time Taken = {(sum(time_taken)/len(time_taken))*1000:.2f}ms\")\n",
        "#     test(model, device, test_loader)"
      ],
      "metadata": {
        "id": "Pr9-12VP-GtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xPDxUfM-GqO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}